---
title: "Chapter 2 Homework"
author: "Kaylynn Hiller"
date: "2026-01-26"
mainfont: "Georgia"
format: 
  html: 
    theme: cosmo
    toc: true
    embed-resources: true
  pdf:
    colorlinks: true
    includes:
      in-header:
    keep-tex: false
header-includes:
  \usepackage{tabularray}
  \usepackage{siunitx}
execute: 
  echo: false
---

## Setup

Assume you are working in an RStudio Project. Use `here::here("data", "filename.csv")` to build file paths to datasets in the `data` folder.

```{r}
library(tidyverse)
library(here)
library(psych)   # used for describe()/describeBy() in a few places
library(broom)
```

```{r}
heart <- read_csv(here::here("data", "heart.csv"))
```

::: callout-tip
If you ever get a “file not found” error, confirm (1) you opened the correct `.Rproj`, and (2) the dataset is inside your project’s data folder (accessed via `here::here("data", ...)`).
:::

## Tutorial (Chapter 2, plus a bit of 3)

### 1) Estimates of variation around the mean

In class, we talked about quantifying variation. Variance and standard deviation are both based on the **sum of squared error (SSE)** around a model’s predictions.

Start by computing the sample standard deviation and sample variance of height:

```{r}
#format data
d <- heart |>
  rename_with(tolower)

# Compute sd and variance of height
d <- d |> 
  drop_na(height) |>
  mutate(height_mean = mean(height),
         height_err = height - height_mean)

sse_height <- sum(d$height_err^2)

var_height <- (sse_height)/(nrow(d) - 1)
sd_height <- sqrt(var_height)

sd_height == sd(d$height)

sd_height
var_height
```

#### Convert variance to standard deviation

Recall: $\text{SD} = \sqrt{\text{Var}}$.

```{r}
# Convert variance to SD using R as a calculator
a <- sd_height^2
a <- round(a, 10)
b <- round(var_height, 10)
a == b
```

#### Compute SSE from the variance and sample size

For the *sample* variance, $$
s^2 = \frac{\text{SSE}}{n-1}
\quad\Rightarrow\quad
\text{SSE} = s^2 (n-1).
$$

```{r}
# Compute n, variance, and then SSE = var * (n - 1)

n <- d |>
  drop_na(height) |>
  summarize(count = n())

SSE <- (n - 1) * var_height
SSE == sse_height

SSE
```

::: callout-tip
In R, `var(x)` uses the sample variance with denominator $n-1$. That’s why the formula above uses $n-1$.
:::

### 2) Estimates of central tendency

Compute mean and median:

```{r}
# Mean and median of height
height_sum <- d |>
  filter(!is.na(height)) |>
  ungroup() |>
  summarize(mean_height = mean(height),
            median_height = median(height))

print(as.data.frame(height_sum), digits = 6)
```

#### Mode (custom helper)

R’s base `mode()` is **not** the statistical mode. Below is a simple helper that returns the most frequent value(s). If the data are multimodal, it returns the average of the modes.

```{r}
mymode <- function(x) {
  x2 <- na.omit(x)
  ux <- unique(x2)
  tab <- tabulate(match(x2, ux))
  mean(ux[tab == max(tab)])
}
```

```{r}
# Use mymode() to compute the mode of height
mode_height <- mymode(d$height)
```

### 3) Group and summarize a dataset

Compute mean and SD of height by gender using tidyverse verbs:

```{r}
# Summarize Height by Gender:
# - n
# - mean height
# - sd height

sum_bygender <- d |>
  drop_na(height, gender) |>
  group_by(gender) |> 
  summarize(count = n(),
            mean_height = mean(height),
            sd_height = sd(height))

sum_bygender
```

If you want a richer descriptive table, `psych::describeBy()` can do that:

```{r}
describeBy(d$height, d$gender, mat = TRUE)
```

::: callout-tip
Even when you use a helper like `describeBy()`, prefer doing **wrangling** (filtering, selecting, mutating, grouping) with tidyverse verbs first, then pass the result to the summary function.
:::

### 4) Estimates of variation revisited: SSE from the data

One way to compute SSE around the **mean model** (predict $\bar{Y}$ for everyone):

```{r}
# Compute SSE around the mean
d <- d |> 
  drop_na(height) |>
  mutate(height_mean = mean(height),
         height_err_mean = height - height_mean)

sse_height_mean <- sum(d$height_err_mean^2)
sse_height_mean
```

Now modify that idea to compute SSE around the **median model** (predict $\tilde{Y}$ for everyone).

```{r}
# Compute SSE around the median
d <- d |> 
  drop_na(height) |>
  mutate(height_median = median(height),
         height_err_median = height - height_median)

sse_height_median <- sum(d$height_err_median^2)
sse_height_median
```

Answer in words: is SSE around the median larger or smaller than SSE around the mean for these data?

The SSE around the median is larger that the SSE around the mean.

### 5) Missing data

Many functions accept `na.rm = TRUE` to ignore missing values.

```{r}
# Example: mean height ignoring missing values
```

You can also drop missing values explicitly:

```{r}
heart |> drop_na(Height) |> summarize(mean_height = mean(Height))
```

## HW 02 Questions

### 1) Central tendency and variability (USNEWS)

The dataset `USNEWS.csv` contains data used by *U.S. News and World Report* to make its college rankings. Two variables of interest are:

-   `gradRate`: graduation rate (percent from 0 to 100)
-   `accptRate`: acceptance rate (proportion from 0 to 1)

For each variable, obtain estimates of central tendency (mean, median, mode) and variability (variance and standard deviation). Write a few sentences describing what you found.

The mean of the graduation rate is relatively close to the median. There is a large amount of standard deviation in the graduation rate as the deviation is 18.8. The mean of the acceptance rate is relatively farther from the median. There is a large amount of standard deviation in the acceptance rate as well as the deviation is 0.161.

```{r}
usnews <- read_csv(here::here("data", "USNEWS.csv"))
```

```{r}
# Create a compact summary table for gradRate and accptRate:
# mean, median, mode, variance, sd, and n (non-missing)
usnews <- usnews |>
  mutate(
    gradRate = as.numeric(gradRate),
    accptRate = as.numeric(accptRate)
  ) |>
  drop_na(gradRate, accptRate)

gradRate_summary <- usnews |>
  summarize(mean_gradRate = mean(gradRate),
            median_gradRate = median(gradRate),
            mode_gradRate = mymode(gradRate),
            var_gradRate = var(gradRate),
            sd_gradRate = sd(gradRate),
            count = n())

accptRate_summary <- usnews |>
  summarize(mean_accptRate = mean(accptRate),
            median_accptRate = median(accptRate),
            mode_accptRate = mymode(accptRate),
            var_accptRate = var(accptRate),
            sd_accptRate = sd(accptRate),
            count = n())

gradRate_summary
accptRate_summary
```

### 2) Conditional vs unconditional predictions (USNEWS)

Another interesting variable is `Type` (public vs private).

1.  Write **Model C** that makes a constant prediction for every school.

```{r}
mod_c <- lm(gradRate ~ 1,
            data = usnews)

tidy(mod_c)
```

2.  Write **Model A** that makes predictions of `gradRate` conditional on `Type`.

```{r}
usnews <- usnews |> 
  mutate(Private = if_else(Type == "Private", 1, 0))

mod_a <- lm(gradRate ~ 1 + Private,
             data = usnews)

tidy(mod_a)
```

3.  As a first look at whether Model A might be useful, compute the mean `gradRate` for private and public schools.
4.  Write a sentence or two describing these results and whether it *appears* useful to move from Model C to Model A.

Model A appears more useful than Model C. The graduation rate for private schools is 16% higher compared to public schools. This large difference means control for the type of school would likely reduce error in the model.

Use both a verbal description and a model statement in LaTeX.

#### Model statements (fill in)

-   Model C (compact): $$
    gradRate_i = b_0 + \varepsilon_i
    $$
-   Model A (augmented; conditional means by type): $$
    gradRate_i = b_0 + b_1 X_i + \varepsilon_i
    $$ where $X_i$ is an indicator you define (e.g., $X_i = 1$ if Private, $0$ if Public).

```{r}
# Compute mean gradRate by Type (and include n)
sum_byType <- usnews |>
  drop_na(gradRate, Type) |>
  group_by(Type) |> 
  summarize(count = n(),
            mean_gradRate = mean(gradRate))
sum_byType
```

### 3) Coupon campaign and store sales (stores)

At 10 grocery stores, a market researcher records the number of cases of a product sold both before and after coupons were mailed to households in the area. The data below are the **changes** in the number of cases sold (positive = more after coupons, negative = fewer, zero = no change).

| Store | Change |
|------:|-------:|
|     A |      5 |
|     B |      4 |
|     C |     -2 |
|     D |      6 |
|     E |      1 |
|     F |      0 |
|     G |     -4 |
|     H |      3 |
|     I |      2 |
|     J |      7 |

#### 3a) By hand

Calculate the **mean** and **standard deviation** for the change scores by hand (or in Excel).

mean = 2.2

standard deviation = 3.521363

(Optional check in R after you finish your by-hand work:)

```{r}
# Create a vector of the change scores and compute mean/sd as a check

store <- letters[1:10]
change <- c(5, 4, -2, 6, 1, 0, -4, 3, 2, 7)

coupons <- tibble(
  store = store,
  change = change
)

coupons

coupons <- coupons |>
  mutate(mean_change = mean(change),
         sd_change = sd(change))

coupons
```

#### 3b) Model C (no change)

Specify a Model C that predicts **no change** for every store.

This model predicts that the change in cases sold is 0 for stores.

Write it in the same form as class:

Let $\Delta_i = \text{the change in the number of cases sold}$.

$$
\Delta_i = 0 + \varepsilon_i
$$

```{r}
# Write Model C in words (in the text), then compute SSE(C) in R later
```

#### 3c) Model A (best constant prediction from the data)

This model predicts the change in cases sold for our sample of stores.

Specify a Model A with one parameter that makes the best possible constant prediction of `Change` based on the data.

$$
\Delta_i = b_0 + \varepsilon_i
$$

```{r}
# Write Model A in words (in the text), then compute SSE(A) in R later
```

#### 3d) Null hypothesis and interpretation

State the null hypothesis tested by comparing Model C and Model A, and give a non-technical interpretation of what the comparison asks.

The null hypothesis assumes there is no change in the number of cases sold when there are coupons (Model C). We are testing to see if the change in the number of cases sold in our sample (Model A) is different from 0. In other words we are comparing the average change in our sample to a null hypothesis assuming there is no change in our sample and therefore the population.

-   **Null hypothesis:** $H_0: b_0 = 0$

#### 3e) Compute error for both models (SSE)

Using SSE as your aggregate measure of error, compute:

-   $\text{SSE}(C)$ for the compact model
-   $\text{SSE}(A)$ for the augmented model

```{r}
# Compute SSE(C) and SSE(A)
coupons <- coupons |> 
  mutate(mod_c_pred = 0,
         mod_c_err = change - mod_c_pred)

sse_c <- sum(coupons$mod_c_err^2) # SSE for model C
sse_c

coupons <- coupons |> 
  mutate(mod_a_pred = mean_change,
         mod_a_err = change - mod_a_pred)

sse_a <- sum(coupons$mod_a_err^2) # SSE for model C
sse_a
```

#### 3f) Proportional reduction in error (PRE)

Compute: $$
\text{PRE} = \frac{\text{SSE}(C) - \text{SSE}(A)}{\text{SSE}(C)}.
$$

Based on this PRE, do you think Model C should be rejected in favor of Model A? (No formal test yet—explain your reasoning.)

We should reject Model C in favor of Model A. While the sample size here is small, the PRE is .3025. This is a relatively large reduction in error for the model.

```{r}
# Compute PRE from SSE(C) and SSE(A)

PRE <- (sse_c - sse_a)/sse_c
PRE
```

#### 3g) Do it again using `stores.csv`

These data are also available in `stores.csv`. Read in the data and use R to obtain all the numbers you calculated above (including PRE if you can).

```{r}
stores <- read_csv(here::here("data", "stores.csv"))
```

```{r}
# Use the stores data to compute:
# - mean and sd of Change
# - SSE(C) where prediction is 0
# - SSE(A) where prediction is mean(Change)
# - PRE

stores <- stores |> 
  mutate(mod_c_pred = 0,
         mod_c_err = Change - mod_c_pred)

sse_c_2 <- sum(stores$mod_c_err^2) # SSE for model C
sse_c_2

stores <- stores |> 
  mutate(mod_a_pred = mean(Change),
         mod_a_err = Change - mod_a_pred)

sse_a_2 <- sum(stores$mod_a_err^2) # SSE for model C
sse_a_2

PRE_2 <- (sse_c_2 - sse_a_2)/sse_c_2
PRE_2
```

::: callout-tip
A convenient SSE pattern is:

-   If predictions are stored in `y_hat`, then `sum((y - y_hat)^2)`.
-   For Model C here, `y_hat` is a constant 0.
-   For Model A here, `y_hat` is a constant equal to `mean(y)`.
:::

### 4) Concept questions

In your own words (**not** using the example from class):

1.  Why is $\text{ERROR}(\text{Model A}) \le \text{ERROR}(\text{Model C})$?

The error for model A is always less than or equal to the error of model C because using a parameter to make an estimation is better than using a random guess. Any information, such as the mean, allows us to make a better prediction than no information where we have to randomly guess.

1.  What is a **degree of freedom**?

A degree of freedom is the number of independent data points in a sample that can vary when estimating parameters. When you have an estimation (such as mean) and know all the data points besides one, the unknown data point can only be one number which produces the known estimation.

### 5) Sampling distributions and small samples

Visit the app:

-   https://correll.shinyapps.io/centralTendency/

5a) Generate four or five iterations using a normally distributed population and samples of $n = 5$.

-   Where do the sampling distributions of the mean peak?
    -   The sampling distributions of the mean peak around 10 with slight variance.
-   How much do the means and medians vary? What minimum and maximum values do you see for each?
    -   The means and medians vary slightly. The medians vary more compared to the means. The minimum value for means is 9.94 and the maximum value is 10.22. The minimum value for the medians is 9.6 and the maximum value is 10.4.
    -   Means: 10.14, 10.18, 9.94, 10.22, 10.03
    -   Medians: 10.4, 9.7, 9.9, 10, 9.6

5b) Answer the same questions for the mean using $n = 500$. (Rescale the histograms so you can see variability.)

-   The sampling distributions of the mean peak around 10.1 with slight variance.
-   The means vary slightly while the medians had no variation. The minimum value for means is 10.07 and the maximum value is 10.12. I got 10.1 for all median values.
-   Means: 10.09, 10.11, 10.12, 10.07, 10.09
-   Medians: 10.1, 10.1, 10.1, 10.1, 10.1

### 6) Central Limit Theorem intuition

Visit the app:

-   https://correll.shinyapps.io/centralLimit/

6a) Set a **skewed** population and draw samples of different sizes. What is the shape of the sampling distribution of the mean for samples of $n = 2$?

The sampling distribution is very right skewed.

6b) What is the shape for $n = 10$?

This sampling is slightly right skewed compared to the previous sampling.

6c) What is the shape for $n = 100$?

This sampling is even less right skewed, but still slightly skewed.
